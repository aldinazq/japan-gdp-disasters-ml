# Japan GDP Growth Forecasting with Natural Disasters (Machine Learning Project)

This repository builds a **reproducible machine learning pipeline** to **forecast Japan’s annual GDP growth** using **lagged disaster aggregates** (EM-DAT) and macro controls. The project emphasizes **time-series validation** best practices (no random shuffling). **Final report:** `project_report.pdf` (LaTeX sources in `report/`).

---

## Prediction Task

- **Target:** `gdp_growth` in year **t** (annual %, Japan)
- **Horizon:** one-year-ahead forecasting
- **Strict ex-ante setup:** to predict `gdp_growth_t`, the model uses only information observable at **t−1**:
  - lagged GDP dynamics: `gdp_growth_lag1`, `gdp_growth_lag2`, rolling mean/std based on past values
  - lagged disaster aggregates: number of events, deaths, damage, magnitude (all at t−1)
  - optional lagged macro controls (WDI): inflation, unemployment, exports/GDP, investment/GDP, FX (all at t−1)
  - optional lagged oil controls: oil price and oil price change (all at t−1)

---

---

## Repository Structure

```text
.
├── AI_USAGE.md
├── PROPOSAL.md
├── README.md
├── project_report.pdf          
├── report/                     (optional: LaTeX sources)
│   ├── main.tex
│   ├── references.bib
│   └── figures/                
├── main.py
├── requirements.txt
├── data/
├── figures/                    (generated by scripts; do not edit manually)
├── results/
├── scripts/
│   └── make_report_figures.py
├── dashboard/
│   └── build_dashboard.py
├── src/
│   ├── __init__.py
│   ├── data_loading.py
│   ├── features.py
│   └── models.py
└── tests/
    ├── test_features.py
    ├── test_pipeline.py
    └── test_models.py```



Key modules:

- `src/data_loading.py`: loads Excel inputs from `data/`
- `src/features.py`: builds the yearly master table and derived features
- `src/models.py`: trains models, runs time-series CV, and writes outputs to `results/`
- `main.py`: CLI entry point to run benchmarks (non-interactive)
- `dashboard/build_dashboard.py`: optional dashboard script
- `tests/`: unit tests for data integrity and pipeline reproducibility

---

## Data

Input files are stored in `data/` (Excel):

- World Bank GDP and GDP growth (Japan)
- EM-DAT disasters for Japan (event-level, aggregated to yearly)
- WDI macro indicators (inflation, unemployment, exports/GDP, investment/GDP, FX)
- Oil price series

**Unit note:** EM-DAT damages are commonly reported in *thousands of USD* (often shown as “'000 US$”). This project converts them to **USD** for consistency.

---

## Setup

## Quickstart (grader-safe)

If you want the shortest, safest run (recommended for graders):

```
python3 -m venv .venv
source .venv/bin/activate
python3 -m pip install -r requirements.txt
python3 -m pytest -q
python3 main.py --only-main

---

## Setup

Create and activate a virtual environment, then install dependencies:

1) Create venv  
`python3 -m venv .venv`

2) Activate  
`source .venv/bin/activate`

3) Install  
`python3 -m pip install --upgrade pip`  
`python3 -m pip install -r requirements.txt`

---

## Run the Project

- Default run:  
  `python3 main.py`

- Main benchmark: strict one-year-ahead forecast:  
  `python3 main.py --mode forecast --covid-mode strict`

- Ex-post mode (for explanation/robustness only):  
  `python3 main.py --mode forecast --covid-mode ex_post`

- Nowcast mode (optional):  
  `python3 main.py --mode nowcast --covid-mode strict`

- Nowcast ex-post (optional):  
  `python3 main.py --mode nowcast --covid-mode ex_post`

- Only run the main block (skip additional robustness runs):  
  `python3 main.py --only-main`

- Hyperparameter tuning (optional):  
  `python3 main.py --tune-rf`  
  `python3 main.py --tune-gb`

- Change the test split ratio:  
  `python3 main.py --test-ratio 0.25`


---

## Outputs (saved in `results/`)

For each run, the pipeline writes files tagged by configuration (e.g., `run_forecast_strict_main`):

- `model_metrics_<tag>.csv`: train/test metrics for each model (RMSE, MAE, R²) + diagnostics
- `cv_scores_<tag>.csv`: fold-level TimeSeriesSplit metrics on the training set
- `predictions_<tag>_<model>.csv`: year-by-year predictions for plots and diagnostics (when produced)


Optional (if tuning is enabled):

- `best_params_random_forest_<tag>.csv`
- `best_params_gradient_boosting_<tag>.csv`

### Post-disaster diagnostics (added value)

In addition to overall test performance, the project reports performance for:

- **post-disaster years:** years where `n_events_lag1 > 0`
- **severe disasters:** defined using a train-only quantile threshold (q = 0.75) on damage_share_gdp_lag1 (no test peeking). The threshold is computed on positive train values when enough positives exist

---

## Dashboard (Optional)

Generate the HTML dashboard (reads saved outputs from `results/`):

`python3 dashboard/build_dashboard.py`

Open all dashboards:

`open dashboard/*.html`

(Option) Build a dashboard for a specific run tag:

`python3 dashboard/build_dashboard.py --tag run_forecast_strict_main`


---

## Report Figures (PNG for LaTeX)

Generate PNG figures for the report (saved to `figures/`):

`python3 scripts/make_report_figures.py --tag run_forecast_strict_main`

Then check:

`ls figures`


---

## Run Tests

`python3 -m pytest -q`


---

## Reproducibility Notes

- No shuffling is used for evaluation (time-based splits only).
- Randomized models use a fixed seed when applicable (`random_state=42`).
- Missing values are handled through imputation inside model pipelines.

---

## AI Tool Usage

AI usage disclosure is provided in `AI_USAGE.md`.
